{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from scorer import add_binary_basement,make_season,score,k_fold_test\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import Lasso,Ridge\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"kc_housing_data_for_feat_engineering_lab.csv\")\n",
    "# Make season column based off the date\n",
    "df = make_season(df)\n",
    "# Make Binary column based off basement sqft -> yes if not zero\n",
    "df = add_binary_basement(df)\n",
    "# drop price (we are predicting log_price)\n",
    "# drop date, should have converted it to date time instead\n",
    "df.drop([\"date\",\"price\"],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create DataFrame with all 2 degree Interactions & Polynomials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new df\n",
    "p = PolynomialFeatures(degree=2).fit(df)\n",
    "features = pd.DataFrame(p.transform(df), columns=p.get_feature_names(df.columns))\n",
    "\n",
    "# Do not include interactions with price_log\n",
    "col_list = list(features.columns)\n",
    "to_remove = list(filter(lambda col : \"price\" in col,col_list))\n",
    "to_remove.remove(\"price_log\")\n",
    "features.drop(to_remove,axis=1,inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create DataFrame with Best Interaction & Best Polynomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the r2 for each feature independently predicting log_price\n",
    "results = []\n",
    "for col in features.columns:\n",
    "    if col != \"price_log\":\n",
    "        model = LinearRegression()\n",
    "        remove_list = list(features.columns)\n",
    "        remove_list.remove(col)\n",
    "        \n",
    "        model.fit(features.drop(remove_list,axis=1),features.price_log)\n",
    "        results.append((col,score(features,model,[col])))\n",
    "\n",
    "# Sort them to find the best interactions\n",
    "best_interaction = sorted(results,key=lambda inst : inst[1],reverse=True)\n",
    "\n",
    "#index 0 is the best interaction, 6 is the best polynomial\n",
    "selected_interactions = [best_interaction[0],best_interaction[6]]\n",
    "selected_model = features.copy()\n",
    "remove_these = list(selected_model.columns)\n",
    "# keep the best interaction\n",
    "for col in selected_interactions:\n",
    "    remove_these.remove(col[0])\n",
    "# keep original features\n",
    "for col in df.columns:\n",
    "    remove_these.remove(col)\n",
    "\n",
    "# Drop all interactions that are not the best\n",
    "selected_model = selected_model.drop(remove_these,axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test\n",
    "With our two new datasets, run some basic Lasso and Ridge models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/noah/anaconda3/envs/learn-env/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.7306040312298105\n",
      "0.793293358348929\n",
      "0.7970408502439861\n",
      "0.8001470546156451\n",
      "0.7752115965185657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/noah/anaconda3/envs/learn-env/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "# First scale both datasets to properly work with Lasso and Ridge\n",
    "scalar = StandardScaler()\n",
    "x = features.drop(\"price_log\",axis=1)\n",
    "x_sel = selected_model.drop(\"price_log\",axis=1)\n",
    "scalar.fit(x)\n",
    "scal_x  = scalar.transform(x)\n",
    "scalar.fit(x_sel)\n",
    "scal_x_sel = scalar.transform(x_sel)\n",
    "\n",
    "# Create the different models to be used\n",
    "las_model_2 = Lasso(alpha=.5)\n",
    "las_model_3 = Lasso(alpha=.05)\n",
    "las_model_4 = Lasso(alpha=.0005)\n",
    "las_model_5 = Lasso(alpha=.00005)\n",
    "rid_model = Ridge()\n",
    "rid_model_sel = Ridge()\n",
    "\n",
    "# Fit all interaction models\n",
    "model1b = las_model_2.fit(scal_x,features.price_log)\n",
    "model1c = las_model_3.fit(scal_x,features.price_log)\n",
    "model1d = las_model_4.fit(scal_x,features.price_log)\n",
    "model1f = las_model_5.fit(scal_x,features.price_log)\n",
    "model2 = rid_model.fit(scal_x,features.price_log)\n",
    "# Fit selected feature model\n",
    "model3 = rid_model_sel.fit(scal_x_sel,selected_model.price_log)\n",
    "\n",
    "# Print results\n",
    "print(score(scal_x,model1b,y=features.price_log))\n",
    "print(score(scal_x,model1c,y=features.price_log))\n",
    "print(score(scal_x,model1d,y=features.price_log))\n",
    "print(score(scal_x,model1f,y=features.price_log))\n",
    "print(score(scal_x,model2,y=features.price_log))\n",
    "print(score(scal_x_sel,model3,y=selected_model.price_log))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do the same thing but now with k fold test train split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha = 0.5\n",
      " -0.003850349159432683\n",
      "alpha = 0.05\n",
      " 0.726832775449655\n",
      "alpha = 0.0005\n",
      " 0.787962857426964\n",
      "Ridge on all features\n",
      " 0.7863567482199495\n",
      "Ridge on selected feature\n",
      " 0.7716325184893597\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Same models as above\n",
    "alphas = [.5,.05,.0005]\n",
    "rid_model = Ridge()\n",
    "rid_model_sel = Ridge()\n",
    "\n",
    "# Run all five models and print results\n",
    "for a in alphas:\n",
    "    print(f\"alpha = {a}\\n\",k_fold_test(Lasso(alpha=a,max_iter = 100000),scal_x,features.price_log,3))\n",
    "print(\"Ridge on all features\\n\",k_fold_test(Ridge(),scal_x,features.price_log,3))\n",
    "print(\"Ridge on selected feature\\n\",k_fold_test(Ridge(),scal_x_sel,selected_model.price_log,3))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
